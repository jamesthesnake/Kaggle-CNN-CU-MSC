{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11848,
          "databundleVersionId": 862157,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This notebook presents a solution to the Histopathologic Cancer Detection challenge on Kaggle, focusing on the detection of cancer in small patches from larger digital pathology scans, utilizing deep learning techniques.\n",
        "\n",
        "##Understanding the Problem:\n",
        "The objective here is to develop a deep learning algorithm capable of identifying metastatic cancer from small image patches extracted from extensive digital pathology scans. Histopathology refers to the examination of disease signs through microscopic analysis of biopsied or surgically removed tissue specimens, which are stained and placed on glass slides for examination under a microscope.\n",
        "\n",
        "Lymph Nodes are vital in this context as they are small glands filtering lymph fluid and often the initial site for the spread of breast cancer. The histological analysis of lymph node metastases is crucial in the TNM Classification, the global standard for assessing cancer spread. Due to the extensive area of tissue needing examination and the potential to overlook small metastases, leveraging Machine Learning offers a promising alternative to enhance both accuracy and efficiency in diagnostics.\n",
        "\n",
        "### Understanding the Data:\n",
        "The dataset for this project is divided into training and testing sets.\n",
        "The Training set comprises 220,000 or so images, while the Test set includes 57,500 or so images.\n",
        "\n",
        "Note that this dataset is a subset of the larger PCam dataset. The PCam dataset is known for its probabilistic sampling, which has led to duplicate images, but the Kaggle version has been refined to remove these duplicates for more effective training and evaluation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Understanding the Images\n",
        "In this competition, you're tasked with predicting labels for images in the test folder. The presence of a positive label signifies that the center 32x32px region of a patch contains at least one pixel of tumor tissue. It's important to note that tumor tissue outside this central region doesn't affect the label. The inclusion of the outer region enables the use of fully-convolutional models without zero-padding, ensuring consistent behavior when applied to a whole-slide image.\n",
        "\n",
        "This problem can be defined as a binary image classification task, where the goal is to differentiate between patches containing tumor tissue and those that do not.\n",
        "\n",
        "## Understanding the Evaluation Metric\n",
        "The evaluation metric used is the Area Under the Receiver Operating Characteristic (ROC) Curve, often abbreviated as AU-ROC or AUC. This metric is crucial for assessing the performance of classification models.\n",
        "\n",
        "The ROC curve is a graphical representation of the model's performance across various threshold settings. It plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity). The AUC score quantifies the model's ability to distinguish between the classes, with higher values indicating better performance.\n",
        "\n",
        "In essence, a high AUC suggests that the model is proficient at correctly identifying positive cases as positive and negative cases as negative. Thus, the AUC serves as a measure of the model's discriminatory power, crucial for tasks like distinguishing between diseased and healthy individuals.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AW_FjRqZANaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 : Adding Dependencies"
      ],
      "metadata": {
        "id": "xemcF5OKANaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import shutil\n",
        "import time\n",
        "import itertools\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import useful sklearn functions\n",
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import Tensorflow functions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "eG7ymao4qtu9",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:23:12.616431Z",
          "iopub.execute_input": "2024-03-18T18:23:12.617093Z",
          "iopub.status.idle": "2024-03-18T18:23:12.628083Z",
          "shell.execute_reply.started": "2024-03-18T18:23:12.617056Z",
          "shell.execute_reply": "2024-03-18T18:23:12.626736Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 : Setting GPU Memory Consumption Growth"
      ],
      "metadata": {
        "id": "_ntJLR2QANaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is just to make sure that Tensorflow will not be using all the memory available, rather it should use what is required."
      ],
      "metadata": {
        "id": "Okqp4n2WANaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "# Grab all the GPUs available on the machine\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: #looping through every potential GPUs here\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "9SZbVAN0y0q_",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:23:16.726507Z",
          "iopub.execute_input": "2024-03-18T18:23:16.727228Z",
          "iopub.status.idle": "2024-03-18T18:23:17.006459Z",
          "shell.execute_reply.started": "2024-03-18T18:23:16.727196Z",
          "shell.execute_reply": "2024-03-18T18:23:17.005360Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 : Loading Dataset from Kaggle\n",
        "\n",
        "We will download the raw zip archive data by using opendatasets library, So lets install that first:"
      ],
      "metadata": {
        "id": "hAPpTXYFrHwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets -q #It will do the installation in quiet mode"
      ],
      "metadata": {
        "id": "dHtAGuLwsCPy",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:23:19.766641Z",
          "iopub.execute_input": "2024-03-18T18:23:19.767232Z",
          "iopub.status.idle": "2024-03-18T18:23:33.826156Z",
          "shell.execute_reply.started": "2024-03-18T18:23:19.767198Z",
          "shell.execute_reply": "2024-03-18T18:23:33.824750Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These files and folders will be downloaded in our local instance:"
      ],
      "metadata": {
        "id": "UhMKC6uTANaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '../input/histopathologic-cancer-detection/'\n",
        "print(os.listdir(base_dir))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T18:23:47.525117Z",
          "iopub.execute_input": "2024-03-18T18:23:47.525512Z",
          "iopub.status.idle": "2024-03-18T18:23:47.531702Z",
          "shell.execute_reply.started": "2024-03-18T18:23:47.525480Z",
          "shell.execute_reply": "2024-03-18T18:23:47.530596Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "TF9rcihvANaZ",
        "outputId": "2b2b65f1-0d55-4485-fbd6-381a08ca018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/histopathologic-cancer-detection/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-583bbab69bd8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/histopathologic-cancer-detection/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/histopathologic-cancer-detection/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you key-in the kaggle crediatials before downloading. Your Kaggle key and password will be required to proceed."
      ],
      "metadata": {
        "id": "5gcKsGQ4ANaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/c/histopathologic-cancer-detection/data\")\n",
        "print(\"Kaggle dataset was successfully downloaded on local instance..............................\")"
      ],
      "metadata": {
        "id": "AD0hKUbSrl1F",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:23:50.405057Z",
          "iopub.execute_input": "2024-03-18T18:23:50.405887Z",
          "iopub.status.idle": "2024-03-18T18:26:19.330370Z",
          "shell.execute_reply.started": "2024-03-18T18:23:50.405857Z",
          "shell.execute_reply": "2024-03-18T18:26:19.329360Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the labels in pandas dataframe:"
      ],
      "metadata": {
        "id": "RNloRKq3ANaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_df = pd.read_csv(\"../input/histopathologic-cancer-detection/train_labels.csv\")\n",
        "full_train_df.head()"
      ],
      "metadata": {
        "id": "xTVdftn9uY2d",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:27:42.388650Z",
          "iopub.execute_input": "2024-03-18T18:27:42.389377Z",
          "iopub.status.idle": "2024-03-18T18:27:42.751340Z",
          "shell.execute_reply.started": "2024-03-18T18:27:42.389346Z",
          "shell.execute_reply": "2024-03-18T18:27:42.750223Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 : Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "q8ygTKjcANab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with the count first. How many images do we have in training as well as test datasets?"
      ],
      "metadata": {
        "id": "dY8vm3BfANab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Size: {}\".format(len(os.listdir('../input/histopathologic-cancer-detection/train/'))))\n",
        "print(\"Test Size: {}\".format(len(os.listdir('../input/histopathologic-cancer-detection/test/'))))"
      ],
      "metadata": {
        "id": "-vKW2HXvurJc",
        "execution": {
          "iopub.status.busy": "2024-03-18T17:59:06.960128Z",
          "iopub.execute_input": "2024-03-18T17:59:06.960498Z",
          "iopub.status.idle": "2024-03-18T17:59:12.325741Z",
          "shell.execute_reply.started": "2024-03-18T17:59:06.960469Z",
          "shell.execute_reply": "2024-03-18T17:59:12.324766Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned on the kaggle website, we have 2,20,025 images in training and 57,458 images in testing folders. Now when we build our model we will only be using training data. Our model should not be seeing the test data at all! So lets check the class distribution of our training dataset first!"
      ],
      "metadata": {
        "id": "2wkRtgoeANac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check the Class Distribution"
      ],
      "metadata": {
        "id": "WwtwTVKGuxoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_count = full_train_df.label.value_counts()\n",
        "\n",
        "# Plot a pie chart to visualize label distribution\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(labels_count, labels=['Healthy', 'Cancer'], startangle=180,\n",
        "        autopct='%1.1f', colors=['#00ff99', '#FF96A7'], shadow=False)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.title('Distribution of Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q_jEa5_Huy8M",
        "execution": {
          "iopub.status.busy": "2024-03-18T17:13:54.774386Z",
          "iopub.execute_input": "2024-03-18T17:13:54.775016Z",
          "iopub.status.idle": "2024-03-18T17:13:54.971903Z",
          "shell.execute_reply.started": "2024-03-18T17:13:54.774986Z",
          "shell.execute_reply": "2024-03-18T17:13:54.971073Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A ratio of 6:4"
      ],
      "metadata": {
        "id": "q0NTSfdiANac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_train_df.shape)"
      ],
      "metadata": {
        "id": "eLOVpeuPu4AO",
        "execution": {
          "iopub.status.busy": "2024-03-18T17:13:58.486417Z",
          "iopub.execute_input": "2024-03-18T17:13:58.487310Z",
          "iopub.status.idle": "2024-03-18T17:13:58.491822Z",
          "shell.execute_reply.started": "2024-03-18T17:13:58.487276Z",
          "shell.execute_reply": "2024-03-18T17:13:58.490908Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set Hyperparameters\n",
        "\n",
        "This step is crucial, and I've experimented with various hyperparameters through multiple iterations to gain insight into my model's performance under different conditions. Given the substantial size of our training data, it's impractical to run the model on the entire dataset each time, especially at the outset. Even with GPUs on Kaggle notebooks, it can take several hours. To mitigate this, I've opted to sample a smaller subset of images, such as 5000 from cancer patients and another 5000 from healthy patients.\n",
        "\n",
        "This sampling strategy ensures a perfectly balanced dataset for both labels, which often leads to improved model performance. Once we're confident in our model's behavior and performance with this smaller dataset, we can then proceed to train the model on larger chunks of data or even the entire dataset if time permits. This staged approach allows us to iterate efficiently and make informed decisions about hyperparameters while managing computational resources effectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IlLO66OIBQ4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 10000 # the number of images we use from each of the two classes\n",
        "IMAGE_SIZE = 96 # This is the pixel dimension of the given images, this is not we are choosing (so not a hyperparameter), it is what it is.\n",
        "EPOCHS = 20 # This is an important hyperparameter, the bigger the better for our model to learn as long as it is not overfitting\n",
        "BATCH_SIZE = 32 # This is an important hyperparameter as well, It tells number of samples to work through before updating the internal model parameters\n",
        "LEARNING_RATE = 0.0003 # This is an important hyperparameter as well, It controls the step size for a model to reach the minimum loss function\n",
        "LR_REDUCE_FACTOR = 0.5 # This hyperparameter helps reducing the learning rate by a factor of 2-10 once learning stagnates."
      ],
      "metadata": {
        "id": "8CjKZ5lyvFaX",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:12.562362Z",
          "iopub.execute_input": "2024-03-18T18:28:12.563218Z",
          "iopub.status.idle": "2024-03-18T18:28:12.568119Z",
          "shell.execute_reply.started": "2024-03-18T18:28:12.563181Z",
          "shell.execute_reply": "2024-03-18T18:28:12.567221Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create the Training and Validation Sets"
      ],
      "metadata": {
        "id": "ae-fTFvSu73m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are building our own dataframe, which is perfectly balanced and also does not contain the entire dataset."
      ],
      "metadata": {
        "id": "fI1h-lCkANad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Take a random sample of class-0 with size equal to number of samples\n",
        "df_0 = full_train_df[full_train_df['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
        "#Take a random sample of class-1 with size equal to number of samples\n",
        "df_1 = full_train_df[full_train_df['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
        "\n",
        "#Concat both the dataframes\n",
        "sampled_df = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
        "#Shuffle them\n",
        "sampled_df = shuffle(sampled_df)\n",
        "#Check the class distribution\n",
        "sampled_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "Bfi_ySktu9IY",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:16.086889Z",
          "iopub.execute_input": "2024-03-18T18:28:16.087261Z",
          "iopub.status.idle": "2024-03-18T18:28:16.154549Z",
          "shell.execute_reply.started": "2024-03-18T18:28:16.087234Z",
          "shell.execute_reply": "2024-03-18T18:28:16.153637Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sampled_df.shape)"
      ],
      "metadata": {
        "id": "0uvWG5hCB85K",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:19.138870Z",
          "iopub.execute_input": "2024-03-18T18:28:19.139242Z",
          "iopub.status.idle": "2024-03-18T18:28:19.144247Z",
          "shell.execute_reply.started": "2024-03-18T18:28:19.139214Z",
          "shell.execute_reply": "2024-03-18T18:28:19.143253Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Directory Structure for Images\n",
        "\n",
        "We'll establish a folder structure for organizing our sample image files. First, we'll create a parent folder named \"PatientImages\". Within this parent folder, we'll create two subfolders: \"cancer_images\" and \"healhty_images\". This organizational setup enables us to segregate our sample image files effectively, which is crucial for loading image data.\n",
        "\n"
      ],
      "metadata": {
        "id": "0NbZMqo0vpea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory\n",
        "base_dir = 'PatientImages'\n",
        "\n",
        "# Check whether the specified path exists or not\n",
        "isExist = os.path.exists(base_dir)\n",
        "if isExist:\n",
        "    #Delete PatientImages if already there\n",
        "    shutil.rmtree('PatientImages')\n",
        "\n",
        "# Create a new directory because it does not exist\n",
        "os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "JJjHZ4Ycvq76",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:21.785380Z",
          "iopub.execute_input": "2024-03-18T18:28:21.785770Z",
          "iopub.status.idle": "2024-03-18T18:28:21.791318Z",
          "shell.execute_reply.started": "2024-03-18T18:28:21.785741Z",
          "shell.execute_reply": "2024-03-18T18:28:21.790434Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# cancer_images\n",
        "cancer_dir = os.path.join(base_dir, 'cancer_images')\n",
        "os.mkdir(cancer_dir)\n",
        "\n",
        "# no_cancer_images\n",
        "no_cancer_dir = os.path.join(base_dir, 'healthy_images')\n",
        "os.mkdir(no_cancer_dir)"
      ],
      "metadata": {
        "id": "SCwdMdFWvzYm",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:24.972929Z",
          "iopub.execute_input": "2024-03-18T18:28:24.973290Z",
          "iopub.status.idle": "2024-03-18T18:28:24.978698Z",
          "shell.execute_reply.started": "2024-03-18T18:28:24.973264Z",
          "shell.execute_reply": "2024-03-18T18:28:24.977746Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check that the sub-folders have been created as expected\n",
        "os.listdir('PatientImages')"
      ],
      "metadata": {
        "id": "DQerpdDAv8u5",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:28.223487Z",
          "iopub.execute_input": "2024-03-18T18:28:28.224082Z",
          "iopub.status.idle": "2024-03-18T18:28:28.230166Z",
          "shell.execute_reply.started": "2024-03-18T18:28:28.224032Z",
          "shell.execute_reply": "2024-03-18T18:28:28.229026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Images into Folders"
      ],
      "metadata": {
        "id": "Fv7eOlhLv_6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_arr = np.array(df_0['id'])\n",
        "df_1_arr = np.array(df_1['id'])"
      ],
      "metadata": {
        "id": "El2gWnIjBipN",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:34.608262Z",
          "iopub.execute_input": "2024-03-18T18:28:34.608588Z",
          "iopub.status.idle": "2024-03-18T18:28:34.614316Z",
          "shell.execute_reply.started": "2024-03-18T18:28:34.608565Z",
          "shell.execute_reply": "2024-03-18T18:28:34.613339Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Iterate over each image ID in df_0_arr\n",
        "for image in df_0_arr:\n",
        "    # Construct the filename by adding the \".tif\" extension\n",
        "    fname = image + '.tif'\n",
        "\n",
        "    # Define the source and destination paths\n",
        "    src = os.path.join('../input/histopathologic-cancer-detection/train/', fname)\n",
        "    dst = os.path.join('PatientImages/healthy_images', fname)\n",
        "\n",
        "    # Copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n"
      ],
      "metadata": {
        "id": "_Uu63xpuDHOr",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:28:37.885975Z",
          "iopub.execute_input": "2024-03-18T18:28:37.886327Z",
          "iopub.status.idle": "2024-03-18T18:29:54.293194Z",
          "shell.execute_reply.started": "2024-03-18T18:28:37.886300Z",
          "shell.execute_reply": "2024-03-18T18:29:54.291989Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer the cancer images\n",
        "for image in df_1_arr:\n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image + '.tif'\n",
        "    # source path to image\n",
        "    src = os.path.join('../input/histopathologic-cancer-detection/train/', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join('PatientImages/cancer_images', fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "e-ljxH3IErnC",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:30:03.020662Z",
          "iopub.execute_input": "2024-03-18T18:30:03.021317Z",
          "iopub.status.idle": "2024-03-18T18:31:18.294420Z",
          "shell.execute_reply.started": "2024-03-18T18:30:03.021285Z",
          "shell.execute_reply": "2024-03-18T18:31:18.293586Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how many training and validation images we have in the folder\n",
        "print(len(os.listdir('PatientImages/cancer_images')))\n",
        "print(len(os.listdir('PatientImages/healthy∆í_images')))\n",
        "\n",
        "# thats a ton"
      ],
      "metadata": {
        "id": "oTcx5G6p4WNj",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:31:21.829440Z",
          "iopub.execute_input": "2024-03-18T18:31:21.829816Z",
          "iopub.status.idle": "2024-03-18T18:31:21.850348Z",
          "shell.execute_reply.started": "2024-03-18T18:31:21.829786Z",
          "shell.execute_reply": "2024-03-18T18:31:21.849413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get rid of  bad images\n",
        "\n",
        "It's essential to identify and remove any corrupt images from our dataset to ensure the quality of our training data. This process is a crucial step in data cleaning for image datasets. Below is how we can accomplish this:\n",
        "\n"
      ],
      "metadata": {
        "id": "aAsGIdm3lzRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "data_dir = 'PatientImages'\n",
        "image_exts = ['tiff', 'tif']\n",
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e:\n",
        "            print('Issue with image {}'.format(image_path))"
      ],
      "metadata": {
        "id": "dmL0jsUsl3wY",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:31:24.836489Z",
          "iopub.execute_input": "2024-03-18T18:31:24.836860Z",
          "iopub.status.idle": "2024-03-18T18:31:27.695890Z",
          "shell.execute_reply.started": "2024-03-18T18:31:24.836829Z",
          "shell.execute_reply": "2024-03-18T18:31:27.694966Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So no more dodgy images so far!"
      ],
      "metadata": {
        "id": "HrngfgITANai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Dataset for Image Processing\n",
        "\n",
        "To generate a new dataset use the following:"
      ],
      "metadata": {
        "id": "Ejp2XnwxLsO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'PatientImages'\n",
        "num_train_samples = SAMPLE_SIZE * 2\n",
        "train_batch_size = BATCH_SIZE\n",
        "val_batch_size = BATCH_SIZE\n",
        "\n",
        "train_steps = None\n",
        "val_steps = None"
      ],
      "metadata": {
        "id": "7zCxPmABp31Z",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:31:51.642152Z",
          "iopub.execute_input": "2024-03-18T18:31:51.642800Z",
          "iopub.status.idle": "2024-03-18T18:31:51.647614Z",
          "shell.execute_reply.started": "2024-03-18T18:31:51.642767Z",
          "shell.execute_reply": "2024-03-18T18:31:51.646553Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255) #Data Scaling\n",
        "alldata_gen = datagen.flow_from_directory(file_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')"
      ],
      "metadata": {
        "id": "JcUn6mawqcHX",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:31:57.967988Z",
          "iopub.execute_input": "2024-03-18T18:31:57.968325Z",
          "iopub.status.idle": "2024-03-18T18:31:58.726745Z",
          "shell.execute_reply.started": "2024-03-18T18:31:57.968301Z",
          "shell.execute_reply": "2024-03-18T18:31:58.725814Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xHvauQyRDIz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the labels that are associated with each index\n",
        "print(alldata_gen.class_indices)"
      ],
      "metadata": {
        "id": "zuxOotErr56S",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:01.870008Z",
          "iopub.execute_input": "2024-03-18T18:32:01.870756Z",
          "iopub.status.idle": "2024-03-18T18:32:01.875376Z",
          "shell.execute_reply.started": "2024-03-18T18:32:01.870724Z",
          "shell.execute_reply": "2024-03-18T18:32:01.874433Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 : Data Visualization - Visualizing Some Training Images\n",
        "\n",
        "Let's see how the images look like for in visuals."
      ],
      "metadata": {
        "id": "YoGVvpQgVWjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgpath =\"histopathologic-cancer-detection/train/\" # training data is stored in this folder\n",
        "malignant = full_train_df.loc[full_train_df['label']==1]['id'].values    # get the ids of malignant cases\n",
        "normal = full_train_df.loc[full_train_df['label']==0]['id'].values       # get the ids of the normal cases"
      ],
      "metadata": {
        "id": "23CJjsYrb-bl",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:06.891120Z",
          "iopub.execute_input": "2024-03-18T18:32:06.891780Z",
          "iopub.status.idle": "2024-03-18T18:32:06.909282Z",
          "shell.execute_reply.started": "2024-03-18T18:32:06.891749Z",
          "shell.execute_reply": "2024-03-18T18:32:06.908232Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def plot_fig(ids,title,nrows=5,ncols=15):\n",
        "\n",
        "    fig,ax = plt.subplots(nrows,ncols,figsize=(18,6))\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    for i,j in enumerate(ids[:nrows*ncols]):\n",
        "        fname = os.path.join(imgpath ,j +'.tif')\n",
        "        img = Image.open(fname)\n",
        "        idcol = ImageDraw.Draw(img)\n",
        "        idcol.rectangle(((0,0),(95,95)),outline='white')\n",
        "        plt.subplot(nrows, ncols, i+1)\n",
        "        plt.imshow(np.array(img))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, y=0.94)"
      ],
      "metadata": {
        "id": "kxQbX-eCcaoY",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:10.858828Z",
          "iopub.execute_input": "2024-03-18T18:32:10.859191Z",
          "iopub.status.idle": "2024-03-18T18:32:10.870972Z",
          "shell.execute_reply.started": "2024-03-18T18:32:10.859164Z",
          "shell.execute_reply": "2024-03-18T18:32:10.870124Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_fig(malignant,'Cancer Cases')"
      ],
      "metadata": {
        "id": "6IlZdtjOcu1D",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:14.691563Z",
          "iopub.execute_input": "2024-03-18T18:32:14.692451Z",
          "iopub.status.idle": "2024-03-18T18:32:17.503401Z",
          "shell.execute_reply.started": "2024-03-18T18:32:14.692416Z",
          "shell.execute_reply": "2024-03-18T18:32:17.501913Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_fig(normal,'Non-Malignant Cases')"
      ],
      "metadata": {
        "id": "xBJ6C-X6c7IF",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:21.741572Z",
          "iopub.execute_input": "2024-03-18T18:32:21.742480Z",
          "iopub.status.idle": "2024-03-18T18:32:24.587882Z",
          "shell.execute_reply.started": "2024-03-18T18:32:21.742436Z",
          "shell.execute_reply": "2024-03-18T18:32:24.586623Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6 : Loading the Test data"
      ],
      "metadata": {
        "id": "qU6oV7HsAflL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a test folder directory structure and copy all test images from the source folder into the 'test_images' subfolder, we can use the following code:\n",
        "\n"
      ],
      "metadata": {
        "id": "TqPB17umANam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create test_dir\n",
        "test_dir = 'test_dir'\n",
        "\n",
        "# Check whether the folder exists or not\n",
        "isExist = os.path.exists(test_dir)\n",
        "if isExist:\n",
        "    shutil.rmtree('test_dir')\n",
        "# Create a new directory because it does not exist\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# create test_images inside test_dir\n",
        "test_images = os.path.join(test_dir, 'test_images')\n",
        "# Create a new directory because it does not exist\n",
        "os.mkdir(test_images)\n",
        "\n",
        "test_path = 'histopathologic-cancer-detection/test'\n",
        "\n",
        "# Transfer the test images into image_dir\n",
        "for image in os.listdir(test_path):\n",
        "    # source path to image\n",
        "    src = os.path.join(test_path, image)\n",
        "    # destination path to image\n",
        "    dst = os.path.join('test_dir/test_images', image)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "cBoeTl_ODORJ",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:29.340106Z",
          "iopub.execute_input": "2024-03-18T18:32:29.340835Z",
          "iopub.status.idle": "2024-03-18T18:32:35.565622Z",
          "shell.execute_reply.started": "2024-03-18T18:32:29.340803Z",
          "shell.execute_reply": "2024-03-18T18:32:35.564630Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many test images we have in the folder\n",
        "print(len(os.listdir('test_dir/test_images')))"
      ],
      "metadata": {
        "id": "ro55PR_bFDMg",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:38.920762Z",
          "iopub.execute_input": "2024-03-18T18:32:38.921128Z",
          "iopub.status.idle": "2024-03-18T18:32:38.963199Z",
          "shell.execute_reply.started": "2024-03-18T18:32:38.921102Z",
          "shell.execute_reply": "2024-03-18T18:32:38.962301Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now load the test data into image data generators."
      ],
      "metadata": {
        "id": "YffiY6FoANam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255) #Data Scaling\n",
        "# Note: shuffle=False causes the test dataset NOT get shuffled\n",
        "test_gen = datagen.flow_from_directory('test_dir',\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)"
      ],
      "metadata": {
        "id": "WmzGqmquGEYU",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:41.840971Z",
          "iopub.execute_input": "2024-03-18T18:32:41.841890Z",
          "iopub.status.idle": "2024-03-18T18:32:43.720517Z",
          "shell.execute_reply.started": "2024-03-18T18:32:41.841855Z",
          "shell.execute_reply": "2024-03-18T18:32:43.719477Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 : Create the Model Architecture\n",
        "\n",
        "We will be building our own deep Convolutional Neural Network from scratch. I am not using any pre-trained models for image classification in this project."
      ],
      "metadata": {
        "id": "CvAXfSDorF9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9TKOFujhrHbX",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:32:48.194640Z",
          "iopub.execute_input": "2024-03-18T18:32:48.195112Z",
          "iopub.status.idle": "2024-03-18T18:32:48.931560Z",
          "shell.execute_reply.started": "2024-03-18T18:32:48.195084Z",
          "shell.execute_reply": "2024-03-18T18:32:48.930716Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8 : Train-Validation Split Data (80% : 20%)"
      ],
      "metadata": {
        "id": "2X-WwYi6sKoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(num_train_samples*.8)\n",
        "val_size = int(num_train_samples*.2)\n",
        "\n",
        "print(f'The Training data size is : {train_size}')\n",
        "print(f'The Validation data size is : {val_size}')\n",
        "\n",
        "train_steps = np.ceil(train_size / train_batch_size)\n",
        "val_steps = np.ceil(val_size / val_batch_size)\n",
        "\n",
        "print(f'The number of Training Steps in each epoch will be : {train_steps}')\n",
        "print(f'The number of Validation Steps in each epoch will be : {val_steps}')"
      ],
      "metadata": {
        "id": "j4_raAwIsMoj",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:10.666345Z",
          "iopub.execute_input": "2024-03-18T18:33:10.666735Z",
          "iopub.status.idle": "2024-03-18T18:33:10.673732Z",
          "shell.execute_reply.started": "2024-03-18T18:33:10.666704Z",
          "shell.execute_reply": "2024-03-18T18:33:10.672507Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we will split the training data into training and validation\n",
        "train = itertools.islice(alldata_gen, train_size)\n",
        "val = itertools.islice(alldata_gen, train_size, train_size + val_size)"
      ],
      "metadata": {
        "id": "F-ymhSSltRiy",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:14.752710Z",
          "iopub.execute_input": "2024-03-18T18:33:14.753074Z",
          "iopub.status.idle": "2024-03-18T18:33:14.757967Z",
          "shell.execute_reply.started": "2024-03-18T18:33:14.753046Z",
          "shell.execute_reply": "2024-03-18T18:33:14.756875Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9 : Train the CNN Model"
      ],
      "metadata": {
        "id": "CiwjPdS2rgxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using Adam optimiser for our model."
      ],
      "metadata": {
        "id": "dqqJ-fmSANan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adam(learning_rate=LEARNING_RATE), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ytg29B45rhV6",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:19.708561Z",
          "iopub.execute_input": "2024-03-18T18:33:19.709261Z",
          "iopub.status.idle": "2024-03-18T18:33:19.730475Z",
          "shell.execute_reply.started": "2024-03-18T18:33:19.709228Z",
          "shell.execute_reply": "2024-03-18T18:33:19.729693Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be creating a folder for our model checkpoint, wherein the best model weights will be saved in that folder."
      ],
      "metadata": {
        "id": "rBFr-xbYANan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory\n",
        "mdl_ckpt = 'Model_Checkpoint'\n",
        "\n",
        "# Check whether the specified path exists or not\n",
        "isExist = os.path.exists(mdl_ckpt)\n",
        "if not isExist:\n",
        "  # Create a new directory because it does not exist\n",
        "  os.mkdir(mdl_ckpt)\n",
        "  print(\"The new directory is created!\")"
      ],
      "metadata": {
        "id": "kMwcxQxkvDg3",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:23.414301Z",
          "iopub.execute_input": "2024-03-18T18:33:23.415141Z",
          "iopub.status.idle": "2024-03-18T18:33:23.420745Z",
          "shell.execute_reply.started": "2024-03-18T18:33:23.415108Z",
          "shell.execute_reply": "2024-03-18T18:33:23.419715Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = ModelCheckpoint(mdl_ckpt, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "7UdlkvO3vMG6",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:27.743205Z",
          "iopub.execute_input": "2024-03-18T18:33:27.743582Z",
          "iopub.status.idle": "2024-03-18T18:33:27.748467Z",
          "shell.execute_reply.started": "2024-03-18T18:33:27.743552Z",
          "shell.execute_reply": "2024-03-18T18:33:27.747414Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a callback to reduce the learning rate when a metric has stopped improving can significantly enhance model training. Typically, models experience performance plateaus, where further training may not yield substantial improvements. In such cases, reducing the learning rate by a factor of 2-10 can help the model navigate these plateaus and continue learning effectively. This callback continuously monitors a specified metric during training and, if no improvement is observed for a defined number of epochs (patience), it adjusts the learning rate accordingly.\n",
        "\n"
      ],
      "metadata": {
        "id": "MZzj1O_hANao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=LR_REDUCE_FACTOR, patience=2, verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "ySUjzxgB7E_w",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:31.384851Z",
          "iopub.execute_input": "2024-03-18T18:33:31.385813Z",
          "iopub.status.idle": "2024-03-18T18:33:31.390381Z",
          "shell.execute_reply.started": "2024-03-18T18:33:31.385773Z",
          "shell.execute_reply": "2024-03-18T18:33:31.389354Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:34.579651Z",
          "iopub.execute_input": "2024-03-18T18:33:34.580521Z",
          "iopub.status.idle": "2024-03-18T18:33:34.584393Z",
          "shell.execute_reply.started": "2024-03-18T18:33:34.580491Z",
          "shell.execute_reply": "2024-03-18T18:33:34.583423Z"
        },
        "trusted": true,
        "id": "3JnCMreUANao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train,\n",
        "                    steps_per_epoch=train_steps,\n",
        "                    validation_data=val,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=EPOCHS, verbose=1,\n",
        "                    callbacks=[model_checkpoint_callback, reduce_lr])"
      ],
      "metadata": {
        "id": "ekekNt9nv2wD",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:33:38.136236Z",
          "iopub.execute_input": "2024-03-18T18:33:38.136894Z",
          "iopub.status.idle": "2024-03-18T18:48:50.844706Z",
          "shell.execute_reply.started": "2024-03-18T18:33:38.136858Z",
          "shell.execute_reply": "2024-03-18T18:48:50.843908Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed a validation accuracy of 89.675%, which is indeed impressive. It's important to note that this result was achieved after training for only 20 epochs and on a subset of 20,000 images. Considering this performance, expanding the training to include all available data and increasing the number of epochs to 50 or more is expected to yield even better results.\n",
        "\n",
        "By utilizing the entire dataset and allowing the model to train for an extended period, we anticipate achieving near-optimal performance, potentially yielding perfect results or approaching them closely. This strategy capitalizes on the larger data volume and longer training duration to further refine the model's performance and enhance its ability to generalize to unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FSTL0n-cANao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9 : Plot Model Performance"
      ],
      "metadata": {
        "id": "FUai-Voa0Wfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(history.history['loss'], color='brown', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], color='green', label='Validation Loss')\n",
        "fig.suptitle('Model Loss Vs Epoch', fontsize=20)\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqgH-m6I0Y0E",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:52:02.770924Z",
          "iopub.execute_input": "2024-03-18T18:52:02.771544Z",
          "iopub.status.idle": "2024-03-18T18:52:02.983478Z",
          "shell.execute_reply.started": "2024-03-18T18:52:02.771510Z",
          "shell.execute_reply": "2024-03-18T18:52:02.982594Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(history.history['accuracy'], color='brown', label='Training ')\n",
        "plt.plot(history.history['val_accuracy'], color='green', label='Validation ')\n",
        "fig.suptitle('Model Accuracy Vs Epoch', fontsize=20)\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eR2T-5TA0so8",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:52:08.502494Z",
          "iopub.execute_input": "2024-03-18T18:52:08.503446Z",
          "iopub.status.idle": "2024-03-18T18:52:08.725863Z",
          "shell.execute_reply.started": "2024-03-18T18:52:08.503408Z",
          "shell.execute_reply": "2024-03-18T18:52:08.724931Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9 : Make a Prediction on Test data"
      ],
      "metadata": {
        "id": "ifXcpbnHG4Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets load the best epoch's weights and do the predictions."
      ],
      "metadata": {
        "id": "3zu2_UybANap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure we are using the best epoch\n",
        "model.load_weights(mdl_ckpt)"
      ],
      "metadata": {
        "id": "a94y5PDdG7ea",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:52:49.846244Z",
          "iopub.execute_input": "2024-03-18T18:52:49.846595Z",
          "iopub.status.idle": "2024-03-18T18:52:49.943251Z",
          "shell.execute_reply.started": "2024-03-18T18:52:49.846571Z",
          "shell.execute_reply": "2024-03-18T18:52:49.942317Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_images = 57458\n",
        "predictions = model.predict(test_gen, steps=num_test_images, verbose=1)\n",
        "\n",
        "# Are the number of predictions correct?It should be 57458.\n",
        "print(f'Total number of predictions = {len(predictions)}')"
      ],
      "metadata": {
        "id": "gZHFyeBWM-aR",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:52:55.849207Z",
          "iopub.execute_input": "2024-03-18T18:52:55.849581Z",
          "iopub.status.idle": "2024-03-18T18:56:21.922396Z",
          "shell.execute_reply.started": "2024-03-18T18:52:55.849550Z",
          "shell.execute_reply": "2024-03-18T18:56:21.921322Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10 : Create Submission File"
      ],
      "metadata": {
        "id": "-KaOo4lrANap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the predictions into a dataframe\n",
        "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
        "\n",
        "# This outputs the file names in the sequence in which\n",
        "# the generator processed the test images.\n",
        "test_filenames = test_gen.filenames\n",
        "\n",
        "# add the filenames to the dataframe\n",
        "df_preds['file_names'] = test_filenames\n",
        "\n",
        "# Create an id column. We will extract the id as shown below\n",
        "# A file name now has this format:\n",
        "# test_images/00006537328c33e284c973d7b39d340809f7271b.tif\n",
        "\n",
        "def extract_id(x):\n",
        "    # split into a list\n",
        "    a = x.split('/')\n",
        "    # split into a list\n",
        "    b = a[1].split('.')\n",
        "    extracted_id = b[0]\n",
        "\n",
        "    return extracted_id\n",
        "\n",
        "df_preds['id'] = df_preds['file_names'].apply(extract_id)"
      ],
      "metadata": {
        "id": "DjYUZdV7NT8Q",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:56:26.567192Z",
          "iopub.execute_input": "2024-03-18T18:56:26.568154Z",
          "iopub.status.idle": "2024-03-18T18:56:26.627558Z",
          "shell.execute_reply.started": "2024-03-18T18:56:26.568121Z",
          "shell.execute_reply": "2024-03-18T18:56:26.626812Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted labels.\n",
        "# We were asked to predict a probability that the image has tumor tissue\n",
        "y_pred = df_preds['has_tumor_tissue']\n",
        "\n",
        "# get the id column\n",
        "image_id = df_preds['id']\n",
        "\n",
        "submission = pd.DataFrame({'id':image_id,  'label':y_pred, }).set_index('id')\n",
        "submission.to_csv('Final_Predictions.csv', columns=['label'])"
      ],
      "metadata": {
        "id": "Qc4D3QzEN7Yv",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:56:33.365945Z",
          "iopub.execute_input": "2024-03-18T18:56:33.366305Z",
          "iopub.status.idle": "2024-03-18T18:56:33.583215Z",
          "shell.execute_reply.started": "2024-03-18T18:56:33.366279Z",
          "shell.execute_reply": "2024-03-18T18:56:33.582141Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head()"
      ],
      "metadata": {
        "id": "-nUUMFYWOIp1",
        "execution": {
          "iopub.status.busy": "2024-03-18T18:56:37.678773Z",
          "iopub.execute_input": "2024-03-18T18:56:37.679730Z",
          "iopub.status.idle": "2024-03-18T18:56:37.689697Z",
          "shell.execute_reply.started": "2024-03-18T18:56:37.679694Z",
          "shell.execute_reply": "2024-03-18T18:56:37.688607Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11 : Final Results"
      ],
      "metadata": {
        "id": "wvxx3QnMANaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I trained my model on 160,000 sample images then I got a kaggle score of 0.8870 as public score. This is what I got on Kaggle :\n",
        "\n",
        "<img src=\"https://github.com/GVworkds/DTSA-5511-Introduction-to-Deep-Learning/blob/main/Leaderboard%20Score-1.png?raw=true\">"
      ],
      "metadata": {
        "id": "Fv68E25PANaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 12 :  Conclusion"
      ],
      "metadata": {
        "id": "fxmYMm7AANaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was a huge dataset for image classification and deep convolutional network helped us classify the images nicely. Sampling was a great way to tune-in our hyperparameters as every iteration took quite a bit to train.\n",
        "\n",
        "<img src=\"https://github.com/jamesthesnake/Kaggle-CNN-CU-MSC/blob/main/Screen%20Shot%202024-03-20%20at%2011.23.08%20AM.png?raw=true\">"
      ],
      "metadata": {
        "id": "Fuju-HgRANaq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8aZZSYBY8Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the current model, we've achieved an impressive AUC score of ~0.89 in predicting breast cancer, indicating its reliability and effectiveness over random guessing. However, there's always room for improvement. Here are a few tweaks we could consider to potentially enhance the model's performance further:\n",
        "\n",
        "Feature Engineering: Analyze the existing features and consider engineering new features that could provide more discriminative information for the model to learn from. This might involve domain expertise or experimentation with various transformations of the existing features.\n",
        "\n",
        "Model Architecture: Experiment with different architectures of the model. Perhaps a deeper or wider neural network could capture more complex patterns in the data. Alternatively, consider using more advanced architectures such as attention mechanisms or graph neural networks if the dataset warrants it.\n",
        "\n",
        "Hyperparameter Tuning: Fine-tune the hyperparameters of the model such as learning rate, batch size, and regularization strength. This can be done through techniques like grid search or random search over a predefined range of values.\n",
        "\n",
        "Data Augmentation: If the dataset is limited in size, consider augmenting it with techniques such as rotation, scaling, or flipping of images. This can help the model generalize better to unseen data.\n",
        "\n",
        "Ensemble Methods: Combine multiple models trained on different subsets of the data or using different algorithms. Ensemble methods often lead to improved performance by leveraging the diversity of individual models.\n",
        "\n",
        "Regularization Techniques: Implement regularization techniques such as dropout or batch normalization to prevent overfitting and improve generalization.\n",
        "\n",
        "Advanced Preprocessing: Explore advanced preprocessing techniques such as feature scaling, normalization, or handling missing values in a more sophisticated manner.\n",
        "\n",
        "Domain-Specific Knowledge: Consult with domain experts to incorporate domain-specific knowledge into the model. This could involve incorporating relevant medical literature or insights from practitioners in the field of breast cancer diagnosis.\n",
        "\n",
        "By carefully implementing these tweaks and iteratively evaluating the model's performance, we can potentially enhance its reliability and predictive power, bringing it closer to achieving an AUC score of 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dETTrnbcANaq"
      }
    }
  ]
}